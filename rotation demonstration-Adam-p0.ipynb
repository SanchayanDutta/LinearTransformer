{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fcfaf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#####################################################\n",
    "# Same as rotation demonstration-Adam.ipynb, except\n",
    "# we additionally enforce that P=0 for each layer\n",
    "#####################################################\n",
    "\n",
    "#use cuda if available, else use cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.cuda.set_device(2)\n",
    "# import the model and some useful functions\n",
    "from linear_transformer import Transformer_F, attention, generate_data, in_context_loss, generate_data_inplace\n",
    "\n",
    "# set up some print options\n",
    "np.set_printoptions(precision = 2, suppress = True)\n",
    "torch.set_printoptions(precision=2)\n",
    "\n",
    "#begin logging\n",
    "cur_dir = 'log' \n",
    "os.makedirs(cur_dir, exist_ok=True)\n",
    "#f = open(cur_dir + '/rotation.log', \"a\", 1)\n",
    "#sys.stdout = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9700bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up problem parameters\n",
    "\n",
    "lr = 0.02\n",
    "clip_r = 0.01\n",
    "alg = 'adam'\n",
    "mode = 'normal'\n",
    "\n",
    "n_layer = 3  # number of layers of transformer\n",
    "N = 20     # context length\n",
    "d = 5        # dimension\n",
    "\n",
    "\n",
    "n_head = 1  # 1-headed attention\n",
    "B = 20000  # 1000 minibatch size\n",
    "var = 0.0001  # initializations scale of transformer parameter\n",
    "shape_k = 0.1  # shape_k: parameter for Gamma distributed covariates\n",
    "max_iters = 30000  # Number of Iterations to run\n",
    "hist_stride = 1  # stride for saved model paramters in `train.ipynb'\n",
    "stride = 100\n",
    "\n",
    "# a convenience function for taking a step and clipping\n",
    "def clip_and_step(allparam, optimizer, clip_r = None):\n",
    "    norm_p=None\n",
    "    grad_all = allparam.grad\n",
    "    if clip_r is not None:\n",
    "        for l in range(grad_all.shape[0]):\n",
    "            for h in range(grad_all.shape[1]):\n",
    "                for t in range(grad_all.shape[2]):\n",
    "                    norm_p = grad_all[l,h,t,:,:].norm().item()\n",
    "                    if norm_p > clip_r:\n",
    "                        grad_all[l,h,t,:,:].mul_(clip_r/norm_p)\n",
    "    optimizer.step()\n",
    "    return norm_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d0ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename_format = '/rotation_hist_adam_pnull_{}_{}_{}.pth'\n",
    "filename = filename_format.format(n_layer, N, d)\n",
    "filename = (cur_dir + filename)\n",
    "hist_dict = {}\n",
    "U_dict = {}\n",
    "D_dict = {}\n",
    "\n",
    "seeds = [0,1,2,3,4]\n",
    "keys = [(s,) for s in seeds]\n",
    "for key in keys:\n",
    "    sd = key[0]\n",
    "    \n",
    "    prob_seed = sd\n",
    "    opt_seed = sd\n",
    "    \n",
    "    hist_dict[key] = []\n",
    "    \n",
    "    #set seed and initialize model\n",
    "    torch.manual_seed(opt_seed)\n",
    "    \n",
    "    model = Transformer_F(n_layer, 1, d, var)\n",
    "    model.to(device)\n",
    "    #initialize algorithm. Important: set beta = 0.9 for adam, 0.999 is very slow\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.99, 0.9), weight_decay=0)\n",
    "    \n",
    "    # set seed\n",
    "    # sample random rotation matrix\n",
    "    # initialize initial training batch\n",
    "    np.random.seed(prob_seed)\n",
    "    torch.manual_seed(prob_seed)\n",
    "    gaus = torch.FloatTensor(5,5).uniform_(-1,1).cuda()\n",
    "    U = torch.linalg.svd (gaus)[0].cuda()\n",
    "    D = torch.diag(torch.FloatTensor([1,1,1/2,1/4,1])).cuda()\n",
    "    U_dict[key]=U\n",
    "    D_dict[key]=D\n",
    "    Z, y = generate_data(mode,N,d,B,shape_k, U, D)\n",
    "    Z = Z.to(device)\n",
    "    y = y.to(device)\n",
    "    for t in range(max_iters):\n",
    "        if t%2000==0 and t>1:# and t < 200001:\n",
    "            optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] *0.5\n",
    "        if t%100==0:\n",
    "            Z,y = generate_data_inplace(Z, U=U, D=D)\n",
    "        start = time.time()\n",
    "        # save model parameters\n",
    "        if t%stride ==0:\n",
    "            hist_dict[key].append(model.allparam.clone().detach())\n",
    "        loss = in_context_loss(model, Z, y)\n",
    "        # compute gradient, take step\n",
    "        loss.backward()\n",
    "        norms = clip_and_step(model.allparam, optimizer, clip_r=clip_r)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #IMPORTANT: zero out the p matrices after each update! This enforces the P=0 constraint.\n",
    "        model.zero_p()\n",
    "\n",
    "        end=time.time()\n",
    "        if t%100 ==0 or t<5:\n",
    "            print('iter {} | Loss: {}  time: {}  gradnorm: {}'.format(t,loss.item(), end-start, norms))\n",
    "#save to \n",
    "torch.save({'hist_dict':hist_dict, 'U_dict':U_dict, 'D_dict':D_dict}, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83154b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# compute test loss\n",
    "####################################\n",
    "#hist_dict = torch.load(filename)['hist_dict']\n",
    "loss_dict = {}\n",
    "for key in hist_dict:\n",
    "    sd = key[0]\n",
    "    \n",
    "    U = U_dict[key]\n",
    "    D = D_dict[key]\n",
    "    \n",
    "    loss_dict[key] = torch.zeros(max_iters//stride)\n",
    "    \n",
    "    np.random.seed(99)\n",
    "    torch.manual_seed(99)\n",
    "    Z, y = generate_data(mode,N,d,B,shape_k,U,D)\n",
    "    Z = Z.to(device)\n",
    "    y = y.to(device)\n",
    "    model = Transformer_F(n_layer, n_head, d, var).to(device)\n",
    "    for t in range(0,max_iters,stride):\n",
    "        with torch.no_grad():\n",
    "            model.allparam.copy_(hist_dict[key][t//stride])\n",
    "        loss_dict[key][t//stride] = in_context_loss(model, Z, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c41abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# plot the test loss with error bars\n",
    "####################################\n",
    "\n",
    "fig_dir = 'figures' \n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize = (9, 7))\n",
    "\n",
    "losses = torch.zeros(len(seeds), max_iters//stride)\n",
    "keys = loss_dict.keys()\n",
    "for idx, key in enumerate(keys):\n",
    "    losses[idx,:] = loss_dict[key].log()\n",
    "losses_mean = torch.mean(losses, axis=0)\n",
    "losses_std = torch.std(losses, axis=0)\n",
    "ax.plot(range(0,max_iters,stride), losses_mean, color = 'blue', lw = 3)#, label='Adam')\n",
    "ax.fill_between(range(0,max_iters,stride), losses_mean-losses_std, losses_mean+losses_std, color = 'black', alpha = 0.2)\n",
    "ax.set_xlabel('Iteration',fontsize=30)\n",
    "ax.set_ylabel('log(Loss)',fontsize=30)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20, width = 3, length = 10)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=20, width = 3, length = 5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + '/rotation_demonstration_adam_pnull_loss_plot.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88adc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# display the parameter matrices\n",
    "# image/font setting assumes d=5\n",
    "####################################\n",
    "\n",
    "key = (0,)\n",
    "\n",
    "U = U_dict[(0,)]\n",
    "D = D_dict[(0,)]\n",
    "UD = torch.mm(U,D)        \n",
    "for l in range(n_layer):\n",
    "    for h in range(n_head):\n",
    "        fig, ax = plt.subplots(1, 1,figsize = (6, 6))\n",
    "        matrix = hist_dict[key][-1][l,h,1,:,:]\n",
    "        #rotate matrix by inverse of UD\n",
    "        matrix = torch.mm(torch.mm(UD.t(), matrix), UD)\n",
    "        # Create a heatmap using imshow\n",
    "        im = ax.imshow(matrix.cpu(), cmap='gray_r')\n",
    "        # Add the matrix values as text\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                ax.text(j, i, format(matrix[i, j], '.2f'), ha='center', va='center', color='r')\n",
    "        # Add a colorbar for reference\n",
    "        fig.colorbar(im)\n",
    "        #ax.set_title('$A_{}$'.format(l),fontsize=20)\n",
    "        plt.savefig(fig_dir + '/rotation_demonstration_pnull_A{}.pdf'.format(l), dpi=600)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a10c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# plot the distance-to-identity of each matrix with time\n",
    "########################################################\n",
    "\n",
    "# function for computing distance to identity\n",
    "def compute_dist_identity(M):\n",
    "    scale = torch.sum(torch.diagonal(M))/M.shape[0]\n",
    "    ideal_identity = scale* torch.eye(M.shape[0]).to(device)\n",
    "    difference = M - ideal_identity\n",
    "    err = (torch.norm(difference,p='fro')/torch.norm(M,p='fro'))\n",
    "    return err\n",
    "\n",
    "########################################\n",
    "# compute distances (assume n_head = 1)\n",
    "########################################\n",
    "dist_dict = {}\n",
    "\n",
    "id_dist_dict={}\n",
    "            \n",
    "for key in hist_dict:\n",
    "    (sd,) = key\n",
    "    dist_dict[key] = torch.zeros(n_layer, 2, max_iters//stride)\n",
    "    id_dist_dict[key] = torch.zeros(n_layer, 2, max_iters//stride)\n",
    "    U = U_dict[key]\n",
    "    D = D_dict[key]\n",
    "    UD = torch.mm(U,D)        \n",
    "    for t in range(0,max_iters,stride):\n",
    "        with torch.no_grad():\n",
    "            allparam = hist_dict[key][t//stride]\n",
    "        for i in range(n_layer):\n",
    "            for j in range(2):\n",
    "                matrix = allparam[i,0,j,:,:]\n",
    "                if j ==1:\n",
    "                    id_dist_dict[key][i,j,t//stride] = compute_dist_identity(matrix).item()\n",
    "                    matrix = torch.mm(torch.mm(UD.t(), matrix), UD)\n",
    "                dist_dict[key][i,j,t//stride] = compute_dist_identity(matrix).item()\n",
    "####################################\n",
    "# plot distances\n",
    "####################################\n",
    "\n",
    "fig_dir = 'figures' \n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "labels = ['$B_0$', '$B_1$', None, \n",
    "          '$\\Sigma^{1/2} A_0 \\Sigma^{1/2}$', \n",
    "          '$\\Sigma^{1/2} A_1 \\Sigma^{1/2}$', \n",
    "          '$\\Sigma^{1/2} A_2 \\Sigma^{1/2}$']\n",
    "names = ['B0', 'B1', None, \n",
    "          'A0', \n",
    "          'A1', \n",
    "          'A2']\n",
    "colors = ['blue','blue',None, 'blue','blue','blue']\n",
    "\n",
    "for l in range(n_layer):\n",
    "    for pq in range(2):\n",
    "        if l==n_layer-1 and pq==0:\n",
    "            continue\n",
    "        if pq ==0:\n",
    "            continue\n",
    "        fig, ax = plt.subplots(1, 1,figsize = (9, 7))\n",
    "        if pq==1:\n",
    "            id_dist_p = torch.zeros(len(seeds), max_iters//stride)\n",
    "            for idx, sd in enumerate(seeds):\n",
    "                losses[idx,:] = id_dist_dict[(sd,)][l,pq,:]\n",
    "            dist_mean = torch.mean(losses, axis=0)\n",
    "            dist_std = torch.std(losses, axis=0)\n",
    "            ax.plot(range(0,max_iters,stride), dist_mean, color = 'red', lw = 3, label='$A_{}$'.format(l))\n",
    "            ax.fill_between(range(0,max_iters,stride), dist_mean-dist_std, dist_mean+dist_std, color = 'red', alpha = 0.2)\n",
    "        \n",
    "        dist_p = torch.zeros(len(seeds), max_iters//stride)\n",
    "        for idx, sd in enumerate(seeds):\n",
    "            losses[idx,:] = dist_dict[(sd,)][l,pq,:]\n",
    "        dist_mean = torch.mean(losses, axis=0)\n",
    "        dist_std = torch.std(losses, axis=0)\n",
    "        \n",
    "        style_id = l + 3*pq\n",
    "        \n",
    "        ax.plot(range(0,max_iters,stride), dist_mean, color = colors[style_id], lw = 3, label=labels[style_id])\n",
    "        ax.fill_between(range(0,max_iters,stride), dist_mean-dist_std, dist_mean+dist_std, color = colors[style_id], alpha = 0.2)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20, width = 3, length = 10)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=20, width = 3, length = 5)\n",
    "        \n",
    "        ax.set_ylim([0,1])\n",
    "        ax.set_xlabel('Iteration',fontsize=30)\n",
    "        ax.set_ylabel('Distance to Id',fontsize=30)\n",
    "        ax.legend(fontsize=30)\n",
    "        \n",
    "        plt.savefig(fig_dir + '/rotation_demonstration_dist_to_id_adam_pnull_{}.pdf'.format(names[style_id]), dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
